{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to genome-grist! genome-grist is software that automates a number of tedious metagenome tasks related to reference-based analyses of Illumina metagenomes. What can genome-grist do? You can use genome-grist to: find out what genomes are in a metagenome! estimate how much of the metagenome will map to reference genomes! map reads to each genome and summarize the results across genomes! summarize the taxonomic composition of a metagenome! genome-grist automates the analysis of public data, and will automatically access metagenomes from the SRA and genomes from Genbank. genome-grist supports both the NCBI and GTDB taxonomies. You can also use your own metagenomes and genomes. Quickstart Please see a genome-grist quickstart . Example figures and output The figure below shows the strain composition of a gut microbiome from the iHMP . This figure was autogenerated by genome-grist; the metagenome and all relevant genomes were downloaded and processed automatically. Configuring genome-grist Please see Configuring a genome-grist project . Running genome-grist You can run genome-grist on a config file like so: genome-grist run <config file> <target> [ <target> ... ] The four top-level targets are: summarize_gather - summarize metagenome contents using sourmash & k-mers summarize_mapping - summarize metagenome contents using mapping summarize_tax - summarize metagenome contents using k-mer-based taxonomy summarize - run summarize_gather , summarize_mapping , and summarize_tax These all produce reports in the reports/ subdir of the configured output dir. You can print out a list of documented targets by omitting the target altogether: genome-grist run <config file> genome-grist has many undocumented intermediate targets. You can print them all out by using run with the target print_rules genome-grist run <config file> print_rules Output files genome-grist produces many different output files with lots of useful information - please see A guide to genome-grist output files ! Additional information Preprints and publications genome-grist was used extensively in the preprint Lightweight compositional analysis of metagenomes with FracMinHash and minimum metagenome covers , Irber et al., 2022. For now, Irber et al., 2022 is the primary citation for genome-grist. Any use of genome-grist should be cited as follows: Lightweight compositional analysis of metagenomes with FracMinHash and minimum metagenome covers. Luiz Carlos Irber, Phillip T Brooks, Taylor E Reiter, N Tessa Pierce-Ward, Mahmudur Rahman Hera, David Koslicki, C. Titus Brown. bioRxiv 2022.01.11.475838; doi:10.1101/2022.01.11.475838 Resource requirements Disk space: genome-grist makes about 3-4 copies of each SRA metagenome analyzed. Memory: the genbank search step on all of genbank takes ~120 GB of RAM. On GTDB, it's much, much less. Other than that, the other steps are all under 10 GB of RAM. Time: This is largely dependent on the size of the metagenome; 100m reads takes a few hours. The processing of multiple data sets can be done in parallel with -j , as well, although you probably want to specify resource limits. For example, here is the command that we use on our HPC: genome-grist run <config> -k --resources mem_mb=145000 -j 16 to run in 150GB of RAM, which will run at most one Genbank search at a time. Support and help We like to support our software! That having been said, genome-grist is still in beta. Please be patient and kind :). Please ask questions and add comments on the github issue tracker for genome-grist . Why the name grist ? 'grist' is in the sourmash family of names (sourmash, wort, distillerycats, etc.) See Grist in Wikipedia . (It is not named for the computing grist !) Installing in developer mode You can run genome-grist from a working directory (e.g. a clone of the git repository) by using pip to install it in editable mode: pip install -e . in which case your genome-grist installation will track changes and updates in the working directory. Or you can pip install the latest version from Github like so: pip install git+https://github.com/dib-lab/genome-grist.git What software and databases does genome-grist use? genome-grist uses the sourmash software extensively, and is built in Python on top of the snakemake workflow system . genome-grist uses fastp and minimap to do error trimming and short-read mapping. Output reports are constructed using Jupyter Notebook and matplotlib . The default search databases used for genome-grist are based on sequences from Genbank and taxonomies from Genbank and GTDB . The databases are provided by the sourmash project . We develop genome-grist at github.com/dib-lab/genome-grist . Support and funding genome-grist was developed with support from Grant GBMF4551 from the Gordon and Betty Moore Foundation, Grant R01HG007513 from the NIH NHGRI, and Grant R03OD030596 from the NIH Common Fund. CTB September 2022","title":"Home"},{"location":"#welcome-to-genome-grist","text":"genome-grist is software that automates a number of tedious metagenome tasks related to reference-based analyses of Illumina metagenomes.","title":"Welcome to genome-grist!"},{"location":"#what-can-genome-grist-do","text":"You can use genome-grist to: find out what genomes are in a metagenome! estimate how much of the metagenome will map to reference genomes! map reads to each genome and summarize the results across genomes! summarize the taxonomic composition of a metagenome! genome-grist automates the analysis of public data, and will automatically access metagenomes from the SRA and genomes from Genbank. genome-grist supports both the NCBI and GTDB taxonomies. You can also use your own metagenomes and genomes.","title":"What can genome-grist do?"},{"location":"#quickstart","text":"Please see a genome-grist quickstart .","title":"Quickstart"},{"location":"#example-figures-and-output","text":"The figure below shows the strain composition of a gut microbiome from the iHMP . This figure was autogenerated by genome-grist; the metagenome and all relevant genomes were downloaded and processed automatically.","title":"Example figures and output"},{"location":"#configuring-genome-grist","text":"Please see Configuring a genome-grist project .","title":"Configuring genome-grist"},{"location":"#running-genome-grist","text":"You can run genome-grist on a config file like so: genome-grist run <config file> <target> [ <target> ... ] The four top-level targets are: summarize_gather - summarize metagenome contents using sourmash & k-mers summarize_mapping - summarize metagenome contents using mapping summarize_tax - summarize metagenome contents using k-mer-based taxonomy summarize - run summarize_gather , summarize_mapping , and summarize_tax These all produce reports in the reports/ subdir of the configured output dir. You can print out a list of documented targets by omitting the target altogether: genome-grist run <config file> genome-grist has many undocumented intermediate targets. You can print them all out by using run with the target print_rules genome-grist run <config file> print_rules","title":"Running genome-grist"},{"location":"#output-files","text":"genome-grist produces many different output files with lots of useful information - please see A guide to genome-grist output files !","title":"Output files"},{"location":"#additional-information","text":"","title":"Additional information"},{"location":"#preprints-and-publications","text":"genome-grist was used extensively in the preprint Lightweight compositional analysis of metagenomes with FracMinHash and minimum metagenome covers , Irber et al., 2022. For now, Irber et al., 2022 is the primary citation for genome-grist. Any use of genome-grist should be cited as follows: Lightweight compositional analysis of metagenomes with FracMinHash and minimum metagenome covers. Luiz Carlos Irber, Phillip T Brooks, Taylor E Reiter, N Tessa Pierce-Ward, Mahmudur Rahman Hera, David Koslicki, C. Titus Brown. bioRxiv 2022.01.11.475838; doi:10.1101/2022.01.11.475838","title":"Preprints and publications"},{"location":"#resource-requirements","text":"Disk space: genome-grist makes about 3-4 copies of each SRA metagenome analyzed. Memory: the genbank search step on all of genbank takes ~120 GB of RAM. On GTDB, it's much, much less. Other than that, the other steps are all under 10 GB of RAM. Time: This is largely dependent on the size of the metagenome; 100m reads takes a few hours. The processing of multiple data sets can be done in parallel with -j , as well, although you probably want to specify resource limits. For example, here is the command that we use on our HPC: genome-grist run <config> -k --resources mem_mb=145000 -j 16 to run in 150GB of RAM, which will run at most one Genbank search at a time.","title":"Resource requirements"},{"location":"#support-and-help","text":"We like to support our software! That having been said, genome-grist is still in beta. Please be patient and kind :). Please ask questions and add comments on the github issue tracker for genome-grist .","title":"Support and help"},{"location":"#why-the-name-grist","text":"'grist' is in the sourmash family of names (sourmash, wort, distillerycats, etc.) See Grist in Wikipedia . (It is not named for the computing grist !)","title":"Why the name grist?"},{"location":"#installing-in-developer-mode","text":"You can run genome-grist from a working directory (e.g. a clone of the git repository) by using pip to install it in editable mode: pip install -e . in which case your genome-grist installation will track changes and updates in the working directory. Or you can pip install the latest version from Github like so: pip install git+https://github.com/dib-lab/genome-grist.git","title":"Installing in developer mode"},{"location":"#what-software-and-databases-does-genome-grist-use","text":"genome-grist uses the sourmash software extensively, and is built in Python on top of the snakemake workflow system . genome-grist uses fastp and minimap to do error trimming and short-read mapping. Output reports are constructed using Jupyter Notebook and matplotlib . The default search databases used for genome-grist are based on sequences from Genbank and taxonomies from Genbank and GTDB . The databases are provided by the sourmash project . We develop genome-grist at github.com/dib-lab/genome-grist .","title":"What software and databases does genome-grist use?"},{"location":"#support-and-funding","text":"genome-grist was developed with support from Grant GBMF4551 from the Gordon and Betty Moore Foundation, Grant R01HG007513 from the NIH NHGRI, and Grant R03OD030596 from the NIH Common Fund. CTB September 2022","title":"Support and funding"},{"location":"configuring/","text":"Configuring a genome-grist project [toc] Overview genome-grist does the following: downloads metagenome data from the SRA, if requested; pre-processes and trims each metagenome; runs sourmash gather on each metagenome, using one or more sourmash databases, to find a minimum metagenome cover ; retrieves the full genomes for any matches and executes a variety of mapping-based analyses; incorporates taxonomy information for the genomes into the taxonomy summary report (if taxonomy reporting is requested). Much of the configuration for genome-grist is about where to find more information about matching genomes - specifically, the genomes, their display names, and their taxonomy. For Genbank genomes, this is easy and genome-grist does it automatically! But if you're providing your own genomes and taxonomy information, it's a bit trickier. Analyzing your own metagenomes You can provide a list of SRA run accessions in the samples: list in the config file, and genome-grist will automatically download, interleave, and trim them for you. If you want to run genome-grist on your own metagenomes, you need to provide one FASTQ file per sample in the trim/ subdirectory of the output directory; for example, for the output directory outputs.private and the sample named podar , you would need to create outputs.private/trim/podar.trim.fq.gz . This should be an interleaved file of Illumina reads, as generated by (for example) seqtk mergepe . The file must start with the sample name and end in trim.fq.gz . Providing correctly-named files will shortcut automatic SRA downloads for these files, and genome-grist will download any remaining samples. If you want to prevent automatic downloading from the SRA completely, you can set the parameter prevent_sra_download: true in the config file. This is a good parameter to set if you are only analyzing your own prepared data! Using Genbank genomes For Genbank genomes, all the necessary information is available already, or automatically determined by genome-grist. sourmash already provides pre-built databases containing all GTDB genomes (R07 rs207) as well as 1.3m Genbank microbial genomes from 2022 . For genomes available through Genbank (aka with Genbank accessions), genome-grist does the genome retrieval automatically, so you don't need to have them downloaded already. Taxonomy spreadsheets are available for both GTDB and Genbank at the Databases page above. Preparing information on local genomes You can provide your own sourmash databases, your own set of genome files and genome information and your own taxonomy spreadsheet to genome-grist, too! This can be useful if you have unpublished or private genomes that you want to use with genome-grist, or if you have large subsets of Genbank already downloaded. Luckily this is all reasonably straightforward and we provide tools to help you! Read on! Note that you can absolutely combine Genbank with your own databases here, or just use your own databases. (If there are overlapping identifiers, the local genomes are chosen first; you might want to do this if you already have a bunch of the Genbank genomes downloaded already, for example.) Choosing identifiers for your genomes You'll need to choose unique identifiers for your genomes. genome-grist requires that your identifier does not have a space, colon (:), or forward slash (/) in it; everything else should be fine. Preparing your genome files You'll need one FASTA file per genome (gzip or bz2 compressed is fine). The filename doesn't matter. It's probably easiest if they're all in one directory, although this isn't necessary. For now, we suggest naming the first sequence in each FASTA file with the genome identifier at the start, space delimited - for example MY_ID_1.1 first_sequence_name is very special . This will allow sourmash to name the resulting signature with the right identifier using --name-from-first (see below). Creating one or more sourmash databases You can mix local databases with genbank databases without fear! You'll need to provide one or more sourmash databases for any local collections, and you do this as usual via the config parameter sourmash_databases , which takes a list of paths to sourmash database locations. To build your own sourmash databases, you'll need sourmash sketches for each genome. Sketch all your genomes (in fna.gz or .fa.gz files) with the following command: sourmash sketch dna -p k=31,scaled=1000 *.gz If you've named your genomes so that the first sequence contains the identifier, you can add --name-from-first and then the signatures will be named the right thing for the next step. If not, you'll need to manually rename of the signatures produced by sourmash sketch . (You can do this with sourmash sig rename , but there's no simple way to do this in bulk.) Once you have all your genome signatures, you can create a sourmash database with sourmash index output.sbt.zip *.sig and then you can cherish and treasure your sourmash database forever! If you have lots of genomes (1000 or more?) we suggest using a workflow system to sketch and rename your genomes appropriately; please ask us for some examples over on the sourmash issue tracker . We chose k=31 above (in the sourmash sketch command) because that matches our default parameters, and we have provided Genbank and GTDB databases for k=31 (as well as k=21 and k=51). But the only real requirement here is that all your databases support the same requested k-mer and scaled sizes. Providing your local genomes to genome-grist You'll also need to provide your local genome files to genome-grist, along with their \"display name\", which will be used in reporting. The information will be provided via the config parameter local_databases_info , which takes a list of paths to info file CSVs. First , genome-grist needs the genome sequences in their own individual files, in one or more directories. The files need to be named by their identifiers in the format {ident}_genomic.fna.gz , and must come with an \"info file\" that contains their identifier, a display name, and the location of the genome file (which must be named as above). genome-grist has a utility to help set this all up! The script genome_grist.copy_local_genomes will take in a list of FASTA files containing genome(s), read the header of the first sequence to find the identifier for that genome, and then copy it into a directory for you. (see \"Step 3\", below, for execution instructions for this script). It will also output a provisional info file, which you can edit. Here's an example of the output of the info file produced by copy_local_genomes : ident,display_name,genome_filename CP001472.1,\"Acidobacterium capsulatum ATCC 51196, complete genome\",databases/podar-ref.d/CP001472.1_genomic.fna.gz CP001941.1,\"Aciduliprofundum boonei T469, complete genome\",databases/podar-ref.d/CP001941.1_genomic.fna.gz CP001097.1,\"Chlorobium limicola DSM 245, complete genome\",databases/podar-ref.d/CP001097.1_genomic.fna.gz Second , for each genome, genome-grist also needs a separate {ident}.info.csv file, containing just the identifier and the display name. This needs to be in the same directory as the genome itself. The utility script genome_grist.make_info_file will produce this for you, based on the whole-database info CSV file created above. (See \"Step 4\", below, for execution instructions for this script.) Here's an example of the output of make_info_file: ; this is the file CP001097.1.info.csv : ident,display_name CP001097.1,\"Chlorobium limicola DSM 245, complete genome\" and the final contents of the databases/podar-ref.d/ directory include: CP001097.1.info.csv CP001472.1_genomic.fna.gz CP001097.1_genomic.fna.gz CP001941.1.info.csv CP001472.1.info.csv CP001941.1_genomic.fna.gz Providing taxonomy information If you want to enable taxonomic summarization for your local genomes, you'll need a taxonomy file that can be read by the sourmash tax subcommands - see the sourmash command-line docs for details. This file contains at least 8 columns, with the headers ident and superkingdom , phylum , class , order , family , genus , species . You provide this file to genome-grist via the config parameter taxonomies , which takes a list of paths to sourmash taxonomy files. Testing it all out We recommend trying this all out with a fake metagenome that's just two of your local genomes concatenated; you can set this up by making the FASTA file and then putting it in your output directory in the subdirectory trim/{sample}.trim.fq.gz , and configuring genome-grist to run summarize_gather on just that sample. So, for example, create a file trim/testme.trim.fq.gz containing a bunch of sequences (FASTA or FASTQ format, despite the filename :) set samples in your config file conf-test.yml to - testme run genome-grist run conf-test.yml summarize_gather and if it all works, then your local database configuration is good! (The output report will be in the reports/report-gather-testme.html subdirectory in your output directory.) You will need to run summarize_tax to test the taxonomy file; the associated output will be in reports/report-taxonomy-testme.html . If you run into any problems, please file an issue! An example for you to try: the podar-ref database Comparative metagenomic and rRNA microbial diversity characterization using archaeal and bacterial synthetic communities, Shakya et al., 2014 made a lovely mock metagenome containing approximately 65 different strains of microbes. Evaluating Metagenome Assembly on a Simple Defined Community with Many Strain Variants, Awad et al., 2017 used sourmash to analyze this community, and produced an updated list of reference genomes that is available for download. While this list of reference genomes is in fact in Genbank, they use non-Genbank identifiers, and so it's a good example data set for \"private\" genomes. So! Let's run through setting up these reference genomes as a local, non-Genbank database for genome-grist to use, and then test it out by applying genome-grist to the mock metagenome! It should take under 10 minutes total to run all the commands. Note: If you have a developer installation of genome-grist , you can run everything below with make test-private in the root genome-grist/ directory. Step 0: Install genome-grist and set up your directory Follow the installation instructions for genome-grist and make sure you're in a conda environment where genome-grist is installed. You will also need sourmash... pip install sourmash and now you should be good to go! Step 1: Download and unpack the podar reference genomes First, we need to get our hands on the genome sequences themselves. The genomes from Awad et al., 2017, are available for download from a project on the Open Science Framework . The following commands will download them and unpack them into the directory databases/podar-ref/ mkdir -p databases/podar-ref curl -L https://osf.io/vbhy5/download -o databases/podar-ref.tar.gz cd databases/podar-ref/ && tar xzf ../podar-ref.tar.gz cd ../../ Step 2: Build sketches and construct a sourmash database genome-grist uses sourmash to generate a minimum metagenome cover containing the best matches to the metagenome, so we need to turn the downloaded genomes into a sourmash database. The following command will sketch all of the .fa files and save the resulting sourmash signatures into databases/podar-ref.zip : sourmash sketch dna -p k=31,scaled=1000 --name-from-first \\ databases/podar-ref/*.fa -o databases/podar-ref.zip note the use of --name-from-first , which names the sketches after the first FASTA header in each file. If you look at the zip file with sourmash sig describe databases/podar-ref.zip , you'll see that all of the signature names start with their accessions, which is what we want. Step 3: Copy the genomes in to a new location with new names Copy the local genomes to a new home that matches genome-grist requirements like so: python -m genome_grist.copy_local_genomes databases/podar-ref/*.fa -o databases/podar-ref.info.csv -d databases/podar-ref.d The subdirectory databases/podar-ref.d/ should now contain 64 genome files, named by their identifiers. There will also be an \"information file\", databases/podar-ref.info.csv , that contains three columns. These were auto-generated by the script from the FASTA files you gave it. You can edit the display_name column and change it to whatever you want; the other columns need to match with other information so please don't change those! Note that display_name is just for display purposes; this allows grist to translate identifiers to (for example) a species and strain name to put on generated graphs. Step 4: Build genome \"info files\" for genome-grist Next, you'll need to create {ident}.info.csv files for each genome. Run: python -m genome_grist.make_info_file databases/podar-ref.info.csv to use the combined info CSV from the previous step to create the necessary info files. The subdirectory databases/podar-ref.d/ should now contain 128 files - 64 genome files, and 64 '.info.csv' files, one for each genome. Step 5: Download the taxonomy file Last but not least, you'll want a taxonomy file for these genomes, in a format that sourmash taxonomy can use. For this data set, you can get it from a project on the Open Science Framework . To download it, run: curl -L https://osf.io/4yhjw/download -o databases/podar-ref.tax.csv This will create a local CSV file with superkingdom, phylum, etc. entries for each of the reference genomes you've downloaded. Step 6: Try it out on a (small) mock metagenome! While you can certainly run this on the entire metagenome from Shakya et al., 2014, that will take a while. So we've prepared a 1m read subset of the data for you to try out! Exciting! You can download this subsetted metagenome like so: mkdir -p outputs.private/trim curl -L https://osf.io/ckbq3/download -o outputs.private/trim/podar.trim.fq.gz and then confirm that the config file conf-private.yml has the following content: samples: - podar outdir: outputs.private/ sourmash_databases: - databases/podar-ref.zip local_databases_info: - databases/podar-ref.info.csv taxonomies: - databases/podar-ref.tax.csv Now run: genome-grist run conf-private.yml summarize_gather summarize_mapping -j 4 -p and (hopefully) it will all work!! Assuming there are no errors and everything is green, look at the HTML files in outputs.private/reports/*.html . Reference: The complete set of config file options The options below can be set and/or overridden in a project specific config file that is passed into genome-grist . Config files can be either YAML or JSON. We suggest YAML since it's nicer to edit. Every genome-grist installation comes with two config files in the conf/ subdirectory of the genome_grist/ Python package, defaults.conf and system.conf . They are read in the order defaults.conf , system.conf , and project-specific config. So, you can ignore the first two and just override options in the project-specific config file. But you can also change the install-wide default parameters in system.conf if you like. You can use showconf to show the current aggregate config like so: genome-grist run conf.yml showconf . An annotated config file # NOTE: all paths are relative to the working directory. ### PROJECT-SPECIFIC PARAMETERS YOU MUST SET FOR EACH PROJECT # samples: a list of metagenome names. REQUIRED. # - the sample names cannot contain periods # - you can use SRA accessions for automatic download, or provide the reads yourself samples: - metagenome_one - metagenome_two # outdir: a directory where all the output will be placed, e.g. outputs.myproject. REQUIRED. # this will be created if it doesn't exist. outdir: some_directory # metagenome_trim_memory: how much memory (RAM) to use when trimming reads with khmer's trim-low-abund. @CTB # set to 1e9 for very low diversity samples, # 10e9 for medium-diversity samples, # and 50e9 if you're foolishly working with soil :) # The default is set to 1e9, which is too low for your data. # WARNING: this much memory _will_ be allocated when running genome-grist! metagenome_trim_memory: 10e9 ### INSTALLATION INFORMATION YOU NEED TO SET AT LEAST ONCE # # These must be set after you install genome-grist and download the various databases. # sourmash_databases: a list of sourmash databases # you'll need to point this at a local download of # databases from e.g. https://sourmash.readthedocs.io/en/latest/databases.html # cannot be empty! sourmash_databases: - /path/to/sourmash-db/database1 - /path/to/sourmash-db/database2 # taxonomies: a list of files to use for taxonomy information. See documentation for `sourmash taxonomy`. # can be empty list, []. taxonomies: - /path/to/taxonomy/files ### INTERMEDIATE CONFIGURATION OPTIONS # # These are ways you can fine-tune genome-grist. # We suggest changing these only once you've successfully run genome-grist a few times! # local_databases_info: a list of database info files for genomes that are local and/or cannot be downloaded from Genbank. # can be empty list, []. # see documentation for more details. local_databases_info: - /path/to/local-sourmash-db/database3.info.csv # prevent_sra_download: turn off download of metagenomes from SRA by sample ID.\" # DEFAULT: false. prevent_sra_download: false # picklist: a --picklist argument to use when searching the sourmash database, to limit which signatures to search. # see sourmash command line documentation for more details. # EXAMPLE: # picklist: some_sig_list.csv:ident:ident picklist: \"\" # skip_genomes: identifiers to ignore when they show up in gather output. # This is useful when the sourmash database contains genomes that are no # longer present in GenBank because they have been deprecated or suppressed. # # Note, in such cases you should try to find a new genome to include in # a local database! # # DEFAULT: [] skip_genomes: [] # sourmash_database_threshold_bp: sets the --threshold-bp minimum match # size of sourmash prefetch and gather. Matches with smaller overlaps # than this will be excluded from consideration. # DEFAULT: 1e5 sourmash_database_threshold_bp: 100000 # sourmash_database_ksize: k-mer size to use when searching sourmash databases. # DEFAULT: 31 sourmash_database_ksize: 31 # sourmash_compute_ksizes: a list of k-mer sizes # to use when creating sketches for samples. should include the database ksize. # DEFAULTS: 21, 31, 15 sourmash_compute_ksizes: - 21 - 31 - 51 # sourmash_scaled: a scaled parameter to use when creating sketches for samples. See sourmash docs for details. # DEFAULT: 1000 sourmash_scaled: 1000 # sourmash_sigtype: 'DNA' or 'protein' - the type of signature to compute for samples. # DEFAULT: DNA sourmash_sigtype: DNA ### SYSTEM SPECIFIC PARAMETERS # # These are good defaults for small projects, but you may # want to change them if you're doing big things on a cluster, or something. # tempdir: a directory where SRA download temporary files will go, e.g. /tmp # new subdirs will be created, used, and then removed. tempdir: some_other_directory # genbank_cache: where genomes downloaded from genbank will be cached. # this needs to be writable by people executing genome-grist; if it's system-wide, suggest making a a+rwxt directory. # DEFAULT ./genbank_cache genbank_cache: ./genbank_cache ### ADVANCED TECHNICAL PARAMETERS # # These probably don't need to be changed unless # you actually run into problems running genome-grist. # prefetch_memory: how much memory to allow for # sourmash prefetch when running genome-grist. # this memory may not actually be used, depending on sourmash databases used. # the default is set for the all-Genbank database. # DEFAULT: 100e9 prefetch_memory: 100e9 More advanced genome-grist usage Where to insert your own files genome-grist is built on top of the snakemake workflow , which lets you substitute your own files in many places. For example, you can put your own {sample}_1.fastq.gz , {sample}_2.fastq.gz , and {sample}_unpaired.fastq.gz files in raw/ to have genome-grist process reads for you. you can put your own interleaved reads file in trim/{sample}.trim.fq.gz to run genome-grist on an unpublished or already-preprocessed set of reads; you can put your own sourmash signature (k=31, scaled=1000) in sigs/{sample}.trim.sig.zip if you want to have it do the database search for you; Please see the genome-grist Snakefile for all the gory details.","title":"Configuring"},{"location":"configuring/#configuring-a-genome-grist-project","text":"[toc]","title":"Configuring a genome-grist project"},{"location":"configuring/#overview","text":"genome-grist does the following: downloads metagenome data from the SRA, if requested; pre-processes and trims each metagenome; runs sourmash gather on each metagenome, using one or more sourmash databases, to find a minimum metagenome cover ; retrieves the full genomes for any matches and executes a variety of mapping-based analyses; incorporates taxonomy information for the genomes into the taxonomy summary report (if taxonomy reporting is requested). Much of the configuration for genome-grist is about where to find more information about matching genomes - specifically, the genomes, their display names, and their taxonomy. For Genbank genomes, this is easy and genome-grist does it automatically! But if you're providing your own genomes and taxonomy information, it's a bit trickier.","title":"Overview"},{"location":"configuring/#analyzing-your-own-metagenomes","text":"You can provide a list of SRA run accessions in the samples: list in the config file, and genome-grist will automatically download, interleave, and trim them for you. If you want to run genome-grist on your own metagenomes, you need to provide one FASTQ file per sample in the trim/ subdirectory of the output directory; for example, for the output directory outputs.private and the sample named podar , you would need to create outputs.private/trim/podar.trim.fq.gz . This should be an interleaved file of Illumina reads, as generated by (for example) seqtk mergepe . The file must start with the sample name and end in trim.fq.gz . Providing correctly-named files will shortcut automatic SRA downloads for these files, and genome-grist will download any remaining samples. If you want to prevent automatic downloading from the SRA completely, you can set the parameter prevent_sra_download: true in the config file. This is a good parameter to set if you are only analyzing your own prepared data!","title":"Analyzing your own metagenomes"},{"location":"configuring/#using-genbank-genomes","text":"For Genbank genomes, all the necessary information is available already, or automatically determined by genome-grist. sourmash already provides pre-built databases containing all GTDB genomes (R07 rs207) as well as 1.3m Genbank microbial genomes from 2022 . For genomes available through Genbank (aka with Genbank accessions), genome-grist does the genome retrieval automatically, so you don't need to have them downloaded already. Taxonomy spreadsheets are available for both GTDB and Genbank at the Databases page above.","title":"Using Genbank genomes"},{"location":"configuring/#preparing-information-on-local-genomes","text":"You can provide your own sourmash databases, your own set of genome files and genome information and your own taxonomy spreadsheet to genome-grist, too! This can be useful if you have unpublished or private genomes that you want to use with genome-grist, or if you have large subsets of Genbank already downloaded. Luckily this is all reasonably straightforward and we provide tools to help you! Read on! Note that you can absolutely combine Genbank with your own databases here, or just use your own databases. (If there are overlapping identifiers, the local genomes are chosen first; you might want to do this if you already have a bunch of the Genbank genomes downloaded already, for example.)","title":"Preparing information on local genomes"},{"location":"configuring/#choosing-identifiers-for-your-genomes","text":"You'll need to choose unique identifiers for your genomes. genome-grist requires that your identifier does not have a space, colon (:), or forward slash (/) in it; everything else should be fine.","title":"Choosing identifiers for your genomes"},{"location":"configuring/#preparing-your-genome-files","text":"You'll need one FASTA file per genome (gzip or bz2 compressed is fine). The filename doesn't matter. It's probably easiest if they're all in one directory, although this isn't necessary. For now, we suggest naming the first sequence in each FASTA file with the genome identifier at the start, space delimited - for example MY_ID_1.1 first_sequence_name is very special . This will allow sourmash to name the resulting signature with the right identifier using --name-from-first (see below).","title":"Preparing your genome files"},{"location":"configuring/#creating-one-or-more-sourmash-databases","text":"You can mix local databases with genbank databases without fear! You'll need to provide one or more sourmash databases for any local collections, and you do this as usual via the config parameter sourmash_databases , which takes a list of paths to sourmash database locations. To build your own sourmash databases, you'll need sourmash sketches for each genome. Sketch all your genomes (in fna.gz or .fa.gz files) with the following command: sourmash sketch dna -p k=31,scaled=1000 *.gz If you've named your genomes so that the first sequence contains the identifier, you can add --name-from-first and then the signatures will be named the right thing for the next step. If not, you'll need to manually rename of the signatures produced by sourmash sketch . (You can do this with sourmash sig rename , but there's no simple way to do this in bulk.) Once you have all your genome signatures, you can create a sourmash database with sourmash index output.sbt.zip *.sig and then you can cherish and treasure your sourmash database forever! If you have lots of genomes (1000 or more?) we suggest using a workflow system to sketch and rename your genomes appropriately; please ask us for some examples over on the sourmash issue tracker . We chose k=31 above (in the sourmash sketch command) because that matches our default parameters, and we have provided Genbank and GTDB databases for k=31 (as well as k=21 and k=51). But the only real requirement here is that all your databases support the same requested k-mer and scaled sizes.","title":"Creating one or more sourmash databases"},{"location":"configuring/#providing-your-local-genomes-to-genome-grist","text":"You'll also need to provide your local genome files to genome-grist, along with their \"display name\", which will be used in reporting. The information will be provided via the config parameter local_databases_info , which takes a list of paths to info file CSVs. First , genome-grist needs the genome sequences in their own individual files, in one or more directories. The files need to be named by their identifiers in the format {ident}_genomic.fna.gz , and must come with an \"info file\" that contains their identifier, a display name, and the location of the genome file (which must be named as above). genome-grist has a utility to help set this all up! The script genome_grist.copy_local_genomes will take in a list of FASTA files containing genome(s), read the header of the first sequence to find the identifier for that genome, and then copy it into a directory for you. (see \"Step 3\", below, for execution instructions for this script). It will also output a provisional info file, which you can edit. Here's an example of the output of the info file produced by copy_local_genomes : ident,display_name,genome_filename CP001472.1,\"Acidobacterium capsulatum ATCC 51196, complete genome\",databases/podar-ref.d/CP001472.1_genomic.fna.gz CP001941.1,\"Aciduliprofundum boonei T469, complete genome\",databases/podar-ref.d/CP001941.1_genomic.fna.gz CP001097.1,\"Chlorobium limicola DSM 245, complete genome\",databases/podar-ref.d/CP001097.1_genomic.fna.gz Second , for each genome, genome-grist also needs a separate {ident}.info.csv file, containing just the identifier and the display name. This needs to be in the same directory as the genome itself. The utility script genome_grist.make_info_file will produce this for you, based on the whole-database info CSV file created above. (See \"Step 4\", below, for execution instructions for this script.) Here's an example of the output of make_info_file: ; this is the file CP001097.1.info.csv : ident,display_name CP001097.1,\"Chlorobium limicola DSM 245, complete genome\" and the final contents of the databases/podar-ref.d/ directory include: CP001097.1.info.csv CP001472.1_genomic.fna.gz CP001097.1_genomic.fna.gz CP001941.1.info.csv CP001472.1.info.csv CP001941.1_genomic.fna.gz","title":"Providing your local genomes to genome-grist"},{"location":"configuring/#providing-taxonomy-information","text":"If you want to enable taxonomic summarization for your local genomes, you'll need a taxonomy file that can be read by the sourmash tax subcommands - see the sourmash command-line docs for details. This file contains at least 8 columns, with the headers ident and superkingdom , phylum , class , order , family , genus , species . You provide this file to genome-grist via the config parameter taxonomies , which takes a list of paths to sourmash taxonomy files.","title":"Providing taxonomy information"},{"location":"configuring/#testing-it-all-out","text":"We recommend trying this all out with a fake metagenome that's just two of your local genomes concatenated; you can set this up by making the FASTA file and then putting it in your output directory in the subdirectory trim/{sample}.trim.fq.gz , and configuring genome-grist to run summarize_gather on just that sample. So, for example, create a file trim/testme.trim.fq.gz containing a bunch of sequences (FASTA or FASTQ format, despite the filename :) set samples in your config file conf-test.yml to - testme run genome-grist run conf-test.yml summarize_gather and if it all works, then your local database configuration is good! (The output report will be in the reports/report-gather-testme.html subdirectory in your output directory.) You will need to run summarize_tax to test the taxonomy file; the associated output will be in reports/report-taxonomy-testme.html . If you run into any problems, please file an issue!","title":"Testing it all out"},{"location":"configuring/#an-example-for-you-to-try-the-podar-ref-database","text":"Comparative metagenomic and rRNA microbial diversity characterization using archaeal and bacterial synthetic communities, Shakya et al., 2014 made a lovely mock metagenome containing approximately 65 different strains of microbes. Evaluating Metagenome Assembly on a Simple Defined Community with Many Strain Variants, Awad et al., 2017 used sourmash to analyze this community, and produced an updated list of reference genomes that is available for download. While this list of reference genomes is in fact in Genbank, they use non-Genbank identifiers, and so it's a good example data set for \"private\" genomes. So! Let's run through setting up these reference genomes as a local, non-Genbank database for genome-grist to use, and then test it out by applying genome-grist to the mock metagenome! It should take under 10 minutes total to run all the commands. Note: If you have a developer installation of genome-grist , you can run everything below with make test-private in the root genome-grist/ directory.","title":"An example for you to try: the podar-ref database"},{"location":"configuring/#step-0-install-genome-grist-and-set-up-your-directory","text":"Follow the installation instructions for genome-grist and make sure you're in a conda environment where genome-grist is installed. You will also need sourmash... pip install sourmash and now you should be good to go!","title":"Step 0: Install genome-grist and set up your directory"},{"location":"configuring/#step-1-download-and-unpack-the-podar-reference-genomes","text":"First, we need to get our hands on the genome sequences themselves. The genomes from Awad et al., 2017, are available for download from a project on the Open Science Framework . The following commands will download them and unpack them into the directory databases/podar-ref/ mkdir -p databases/podar-ref curl -L https://osf.io/vbhy5/download -o databases/podar-ref.tar.gz cd databases/podar-ref/ && tar xzf ../podar-ref.tar.gz cd ../../","title":"Step 1: Download and unpack the podar reference genomes"},{"location":"configuring/#step-2-build-sketches-and-construct-a-sourmash-database","text":"genome-grist uses sourmash to generate a minimum metagenome cover containing the best matches to the metagenome, so we need to turn the downloaded genomes into a sourmash database. The following command will sketch all of the .fa files and save the resulting sourmash signatures into databases/podar-ref.zip : sourmash sketch dna -p k=31,scaled=1000 --name-from-first \\ databases/podar-ref/*.fa -o databases/podar-ref.zip note the use of --name-from-first , which names the sketches after the first FASTA header in each file. If you look at the zip file with sourmash sig describe databases/podar-ref.zip , you'll see that all of the signature names start with their accessions, which is what we want.","title":"Step 2: Build sketches and construct a sourmash database"},{"location":"configuring/#step-3-copy-the-genomes-in-to-a-new-location-with-new-names","text":"Copy the local genomes to a new home that matches genome-grist requirements like so: python -m genome_grist.copy_local_genomes databases/podar-ref/*.fa -o databases/podar-ref.info.csv -d databases/podar-ref.d The subdirectory databases/podar-ref.d/ should now contain 64 genome files, named by their identifiers. There will also be an \"information file\", databases/podar-ref.info.csv , that contains three columns. These were auto-generated by the script from the FASTA files you gave it. You can edit the display_name column and change it to whatever you want; the other columns need to match with other information so please don't change those! Note that display_name is just for display purposes; this allows grist to translate identifiers to (for example) a species and strain name to put on generated graphs.","title":"Step 3: Copy the genomes in to a new location with new names"},{"location":"configuring/#step-4-build-genome-info-files-for-genome-grist","text":"Next, you'll need to create {ident}.info.csv files for each genome. Run: python -m genome_grist.make_info_file databases/podar-ref.info.csv to use the combined info CSV from the previous step to create the necessary info files. The subdirectory databases/podar-ref.d/ should now contain 128 files - 64 genome files, and 64 '.info.csv' files, one for each genome.","title":"Step 4: Build genome \"info files\" for genome-grist"},{"location":"configuring/#step-5-download-the-taxonomy-file","text":"Last but not least, you'll want a taxonomy file for these genomes, in a format that sourmash taxonomy can use. For this data set, you can get it from a project on the Open Science Framework . To download it, run: curl -L https://osf.io/4yhjw/download -o databases/podar-ref.tax.csv This will create a local CSV file with superkingdom, phylum, etc. entries for each of the reference genomes you've downloaded.","title":"Step 5: Download the taxonomy file"},{"location":"configuring/#step-6-try-it-out-on-a-small-mock-metagenome","text":"While you can certainly run this on the entire metagenome from Shakya et al., 2014, that will take a while. So we've prepared a 1m read subset of the data for you to try out! Exciting! You can download this subsetted metagenome like so: mkdir -p outputs.private/trim curl -L https://osf.io/ckbq3/download -o outputs.private/trim/podar.trim.fq.gz and then confirm that the config file conf-private.yml has the following content: samples: - podar outdir: outputs.private/ sourmash_databases: - databases/podar-ref.zip local_databases_info: - databases/podar-ref.info.csv taxonomies: - databases/podar-ref.tax.csv Now run: genome-grist run conf-private.yml summarize_gather summarize_mapping -j 4 -p and (hopefully) it will all work!! Assuming there are no errors and everything is green, look at the HTML files in outputs.private/reports/*.html .","title":"Step 6: Try it out on a (small) mock metagenome!"},{"location":"configuring/#reference-the-complete-set-of-config-file-options","text":"The options below can be set and/or overridden in a project specific config file that is passed into genome-grist . Config files can be either YAML or JSON. We suggest YAML since it's nicer to edit. Every genome-grist installation comes with two config files in the conf/ subdirectory of the genome_grist/ Python package, defaults.conf and system.conf . They are read in the order defaults.conf , system.conf , and project-specific config. So, you can ignore the first two and just override options in the project-specific config file. But you can also change the install-wide default parameters in system.conf if you like. You can use showconf to show the current aggregate config like so: genome-grist run conf.yml showconf .","title":"Reference: The complete set of config file options"},{"location":"configuring/#an-annotated-config-file","text":"# NOTE: all paths are relative to the working directory. ### PROJECT-SPECIFIC PARAMETERS YOU MUST SET FOR EACH PROJECT # samples: a list of metagenome names. REQUIRED. # - the sample names cannot contain periods # - you can use SRA accessions for automatic download, or provide the reads yourself samples: - metagenome_one - metagenome_two # outdir: a directory where all the output will be placed, e.g. outputs.myproject. REQUIRED. # this will be created if it doesn't exist. outdir: some_directory # metagenome_trim_memory: how much memory (RAM) to use when trimming reads with khmer's trim-low-abund. @CTB # set to 1e9 for very low diversity samples, # 10e9 for medium-diversity samples, # and 50e9 if you're foolishly working with soil :) # The default is set to 1e9, which is too low for your data. # WARNING: this much memory _will_ be allocated when running genome-grist! metagenome_trim_memory: 10e9 ### INSTALLATION INFORMATION YOU NEED TO SET AT LEAST ONCE # # These must be set after you install genome-grist and download the various databases. # sourmash_databases: a list of sourmash databases # you'll need to point this at a local download of # databases from e.g. https://sourmash.readthedocs.io/en/latest/databases.html # cannot be empty! sourmash_databases: - /path/to/sourmash-db/database1 - /path/to/sourmash-db/database2 # taxonomies: a list of files to use for taxonomy information. See documentation for `sourmash taxonomy`. # can be empty list, []. taxonomies: - /path/to/taxonomy/files ### INTERMEDIATE CONFIGURATION OPTIONS # # These are ways you can fine-tune genome-grist. # We suggest changing these only once you've successfully run genome-grist a few times! # local_databases_info: a list of database info files for genomes that are local and/or cannot be downloaded from Genbank. # can be empty list, []. # see documentation for more details. local_databases_info: - /path/to/local-sourmash-db/database3.info.csv # prevent_sra_download: turn off download of metagenomes from SRA by sample ID.\" # DEFAULT: false. prevent_sra_download: false # picklist: a --picklist argument to use when searching the sourmash database, to limit which signatures to search. # see sourmash command line documentation for more details. # EXAMPLE: # picklist: some_sig_list.csv:ident:ident picklist: \"\" # skip_genomes: identifiers to ignore when they show up in gather output. # This is useful when the sourmash database contains genomes that are no # longer present in GenBank because they have been deprecated or suppressed. # # Note, in such cases you should try to find a new genome to include in # a local database! # # DEFAULT: [] skip_genomes: [] # sourmash_database_threshold_bp: sets the --threshold-bp minimum match # size of sourmash prefetch and gather. Matches with smaller overlaps # than this will be excluded from consideration. # DEFAULT: 1e5 sourmash_database_threshold_bp: 100000 # sourmash_database_ksize: k-mer size to use when searching sourmash databases. # DEFAULT: 31 sourmash_database_ksize: 31 # sourmash_compute_ksizes: a list of k-mer sizes # to use when creating sketches for samples. should include the database ksize. # DEFAULTS: 21, 31, 15 sourmash_compute_ksizes: - 21 - 31 - 51 # sourmash_scaled: a scaled parameter to use when creating sketches for samples. See sourmash docs for details. # DEFAULT: 1000 sourmash_scaled: 1000 # sourmash_sigtype: 'DNA' or 'protein' - the type of signature to compute for samples. # DEFAULT: DNA sourmash_sigtype: DNA ### SYSTEM SPECIFIC PARAMETERS # # These are good defaults for small projects, but you may # want to change them if you're doing big things on a cluster, or something. # tempdir: a directory where SRA download temporary files will go, e.g. /tmp # new subdirs will be created, used, and then removed. tempdir: some_other_directory # genbank_cache: where genomes downloaded from genbank will be cached. # this needs to be writable by people executing genome-grist; if it's system-wide, suggest making a a+rwxt directory. # DEFAULT ./genbank_cache genbank_cache: ./genbank_cache ### ADVANCED TECHNICAL PARAMETERS # # These probably don't need to be changed unless # you actually run into problems running genome-grist. # prefetch_memory: how much memory to allow for # sourmash prefetch when running genome-grist. # this memory may not actually be used, depending on sourmash databases used. # the default is set for the all-Genbank database. # DEFAULT: 100e9 prefetch_memory: 100e9","title":"An annotated config file"},{"location":"configuring/#more-advanced-genome-grist-usage","text":"","title":"More advanced genome-grist usage"},{"location":"configuring/#where-to-insert-your-own-files","text":"genome-grist is built on top of the snakemake workflow , which lets you substitute your own files in many places. For example, you can put your own {sample}_1.fastq.gz , {sample}_2.fastq.gz , and {sample}_unpaired.fastq.gz files in raw/ to have genome-grist process reads for you. you can put your own interleaved reads file in trim/{sample}.trim.fq.gz to run genome-grist on an unpublished or already-preprocessed set of reads; you can put your own sourmash signature (k=31, scaled=1000) in sigs/{sample}.trim.sig.zip if you want to have it do the database search for you; Please see the genome-grist Snakefile for all the gory details.","title":"Where to insert your own files"},{"location":"output-guide/","text":"A guide to genome-grist output files genome-grist runs many steps and because of that it creates a lot of output files. In brief, genome-grist can do some or all of the following steps: downloads and trims metagenomes from the SRA; runs sourmash gather on Genbank or GTDB databases to find genomes; downloads matching genomes from Genbank; maps metagenome reads to the downloaded genomes; does a second round of mapping that ensures reads are not double-counted; produces summary reports of metagenome composition, taxonomy, and mapping; and each of these steps has its own set of outputs. Below is a guide to the various outputs! We welcome questions and comments; please ask questions in the genome-grist issue tracker as you have them! Configuring your output directory genome-grist places all files in the {outdir} folder, which must be set in the config file; for example, if your config file contains outdir: outputs.metag then all of the directories below will be created under outputs.metag/ . Files and subdirectories within {outdir} Below, we use \"sample\" and \"metagenome\" interchangeably. Metagenome reads {outdir}/raw/ - untrimmed reads, from the SRA or private sequencing. {outdir}/trim/ - adapter and quality-trimmed reads, starting from raw/ ; inputs into downstream steps. {outdir}/abundtrim/ - optional output of variable-coverage k-mer trimming; not used in genome-grist. sourmash output {outdir}/sigs/ - sourmash sketches calculated from trimmed reads in {outdir}/trim/ . {outdir}/gather/ - sourmash outputs; see details below. Genomes and mapping information {outdir}/genomes/ - sequence files and associated information for any genomes found in a sample. {outdir}/mapping/ - mapping results for sample reads to genomes. {outdir}/leftover/ - \"leftover\" mapping results for second-pass mapping; see details below. Reporting and summary output {outdir}/reports/ - summary reports of sourmash gather output, minimap output, and sourmash taxonomy. {outdir}/{sample}.info.yaml - summary information on each sample Second-pass mapping - the files in leftover/ genome-grist actually does two different rounds of mapping. The first round is straightforward mapping: all reads are mapped to all genomes. In brief, the metagenome reads are mapped to all genomes from the minimum metagenome cover generated by sourmash gather . All of the statistics and outputs in the {outdir}/mapping/ location come from this process. Crucially, during this process, reads may map to more than one genome. There is no specialized handling of multi-mapping reads. During the second pass of mapping, this changes! For the second round, grist does the following prior to generating the mapping results in the leftover/ directory. 1. for the first genome in the gather results, 2. maps reads to that genome 3. removes those reads from further consideration for mapping, 4. and then proceeds to the second step. In effect, what this means is that if there's a region shared between multiple genomes in the minimum metagenome cover, all of the reads that would map to the shared region are \"claimed\" by the genome that is ranked earlier in the gather results. Reads that did map to such a shared region but were claimed by an earlier genome are saved for each genome to a file with the extension overlap.fq.gz within the mapping/ directory; reads that will be mapped to a particular genome are saved in a file leftover.fq.gz , also within the mapping/ directory. To summarize: under the mapping/ directory, the mapped.fq.gz files contain all the reads that map to the genomes; the leftover.fq.gz files contain the subset of mapped reads that will be mapped to that genome in the second round; the overlap.fq.gz files contain the subset of mapped reads that were removed from consideration due to overlap with an earlier rank genome; Then, the leftover/ directory contains the mapping results for the leftover.fq.gz . A key outcome of this is that read mapping information under mapping/ includes multimapped reads . So you can't just e.g. sum the numbers of mapped reads from that directory, or you may be double-counting some reads. However, the read mapping information under leftover/ only counts each read once , so you can work with those numbers more easily. Details of specific output files sourmash outputs Primary outputs: {outdir}/gather/{sample}.gather.csv - CSV output of sourmash gather {outdir}/gather/{sample}.gather.out - human-readable output of sourmash gather {outdir}/gather/{sample}.gather.with-lineages.csv - gather CSV annotated with taxonomy Interim outputs that are used or summarized elsewhere: {outdir}/gather/{sample}.prefetch.csv - CSV output of sourmash prefetch {outdir}/gather/{sample}.genomes.info.csv - summary information on matching genomes {outdir}/gather/{sample}.prefetch.report.txt - summary of prefetch information {outdir}/gather/{sample}.known.sig.gz - known sourmash hashes {outdir}/gather/{sample}.unknown.sig.gz - unknown sourmash hashes mapping outputs mapping/ and leftover/ subdirectory files {sample_id}.summary.csv - summary of the mapping. See below for details. {sample_id}.x.{genome_id}.bam - output of mapping {sample_id}.x.{genome_id}.depth.txt - output of samtools depth {sample_id}.x.{genome_id}.count_mapped_reads.txt - output of samtools view -c {sample_id}.x.{genome_id}.leftover.fq.gz - reads remaining after reads from earlier-rank gather results are mapped (only in mapping/ subdirectory) {sample_id}.x.{genome_id}.mapped.fq.gz - all of the mapped reads {sample_id}.x.{genome_id}.overlap.fq.gz - ... {sample_id}.x.{genome_id}.bcf - output of samtools mpileup and samtools call (BCF file) {sample_id}.x.{genome_id}.vcf.gz - output of samtools mpileup and samtools call (VCF file) {sample_id}.x.{genome_id}.vcf.gz.csi - ancillary output of samtools mpileup and samtools call mapping summary file: {metagenome}.summary.csv in /mapping/ and /leftover/ these files are produced by genome_grist/summarize_mapping.py and contains one row for each genome in {metagenome} , with the following columns: index - index column unique to each row. Equivalent to genome_id . genome_id - genome identifier. sample_id - metagenome/sample identifier. n_chrom - number of contigs in the genome. n_snps - number of SNPs in the genome relative to the metagenome reads (as called by samtools call ). n_genome_bp - size of genome in bp. n_missed_bp - the number of positions in the genome with 0 coverage. f_missed_bp - the fraction of the genome that has no matches: missed / genome_bp . avg_coverage - average coverage of genome; includes bases with 0 coverage. effective_coverage - sum of depth divided by number of covered bases; does not include bases with 0 coverage. n_covered_bp - the number of bp covered by at least one read. f_covered_bp - fraction of bp covered by at least one read, aka read-mapping-based \"detection\". n_mapped_reads - total count of primary mapped reads.","title":"Output files"},{"location":"output-guide/#a-guide-to-genome-grist-output-files","text":"genome-grist runs many steps and because of that it creates a lot of output files. In brief, genome-grist can do some or all of the following steps: downloads and trims metagenomes from the SRA; runs sourmash gather on Genbank or GTDB databases to find genomes; downloads matching genomes from Genbank; maps metagenome reads to the downloaded genomes; does a second round of mapping that ensures reads are not double-counted; produces summary reports of metagenome composition, taxonomy, and mapping; and each of these steps has its own set of outputs. Below is a guide to the various outputs! We welcome questions and comments; please ask questions in the genome-grist issue tracker as you have them!","title":"A guide to genome-grist output files"},{"location":"output-guide/#configuring-your-output-directory","text":"genome-grist places all files in the {outdir} folder, which must be set in the config file; for example, if your config file contains outdir: outputs.metag then all of the directories below will be created under outputs.metag/ .","title":"Configuring your output directory"},{"location":"output-guide/#files-and-subdirectories-within-outdir","text":"Below, we use \"sample\" and \"metagenome\" interchangeably.","title":"Files and subdirectories within {outdir}"},{"location":"output-guide/#metagenome-reads","text":"{outdir}/raw/ - untrimmed reads, from the SRA or private sequencing. {outdir}/trim/ - adapter and quality-trimmed reads, starting from raw/ ; inputs into downstream steps. {outdir}/abundtrim/ - optional output of variable-coverage k-mer trimming; not used in genome-grist.","title":"Metagenome reads"},{"location":"output-guide/#sourmash-output","text":"{outdir}/sigs/ - sourmash sketches calculated from trimmed reads in {outdir}/trim/ . {outdir}/gather/ - sourmash outputs; see details below.","title":"sourmash output"},{"location":"output-guide/#genomes-and-mapping-information","text":"{outdir}/genomes/ - sequence files and associated information for any genomes found in a sample. {outdir}/mapping/ - mapping results for sample reads to genomes. {outdir}/leftover/ - \"leftover\" mapping results for second-pass mapping; see details below.","title":"Genomes and mapping information"},{"location":"output-guide/#reporting-and-summary-output","text":"{outdir}/reports/ - summary reports of sourmash gather output, minimap output, and sourmash taxonomy. {outdir}/{sample}.info.yaml - summary information on each sample","title":"Reporting and summary output"},{"location":"output-guide/#second-pass-mapping-the-files-in-leftover","text":"genome-grist actually does two different rounds of mapping. The first round is straightforward mapping: all reads are mapped to all genomes. In brief, the metagenome reads are mapped to all genomes from the minimum metagenome cover generated by sourmash gather . All of the statistics and outputs in the {outdir}/mapping/ location come from this process. Crucially, during this process, reads may map to more than one genome. There is no specialized handling of multi-mapping reads. During the second pass of mapping, this changes! For the second round, grist does the following prior to generating the mapping results in the leftover/ directory. 1. for the first genome in the gather results, 2. maps reads to that genome 3. removes those reads from further consideration for mapping, 4. and then proceeds to the second step. In effect, what this means is that if there's a region shared between multiple genomes in the minimum metagenome cover, all of the reads that would map to the shared region are \"claimed\" by the genome that is ranked earlier in the gather results. Reads that did map to such a shared region but were claimed by an earlier genome are saved for each genome to a file with the extension overlap.fq.gz within the mapping/ directory; reads that will be mapped to a particular genome are saved in a file leftover.fq.gz , also within the mapping/ directory. To summarize: under the mapping/ directory, the mapped.fq.gz files contain all the reads that map to the genomes; the leftover.fq.gz files contain the subset of mapped reads that will be mapped to that genome in the second round; the overlap.fq.gz files contain the subset of mapped reads that were removed from consideration due to overlap with an earlier rank genome; Then, the leftover/ directory contains the mapping results for the leftover.fq.gz . A key outcome of this is that read mapping information under mapping/ includes multimapped reads . So you can't just e.g. sum the numbers of mapped reads from that directory, or you may be double-counting some reads. However, the read mapping information under leftover/ only counts each read once , so you can work with those numbers more easily.","title":"Second-pass mapping - the files in leftover/"},{"location":"output-guide/#details-of-specific-output-files","text":"","title":"Details of specific output files"},{"location":"output-guide/#sourmash-outputs","text":"Primary outputs: {outdir}/gather/{sample}.gather.csv - CSV output of sourmash gather {outdir}/gather/{sample}.gather.out - human-readable output of sourmash gather {outdir}/gather/{sample}.gather.with-lineages.csv - gather CSV annotated with taxonomy Interim outputs that are used or summarized elsewhere: {outdir}/gather/{sample}.prefetch.csv - CSV output of sourmash prefetch {outdir}/gather/{sample}.genomes.info.csv - summary information on matching genomes {outdir}/gather/{sample}.prefetch.report.txt - summary of prefetch information {outdir}/gather/{sample}.known.sig.gz - known sourmash hashes {outdir}/gather/{sample}.unknown.sig.gz - unknown sourmash hashes","title":"sourmash outputs"},{"location":"output-guide/#mapping-outputs","text":"","title":"mapping outputs"},{"location":"output-guide/#mapping-and-leftover-subdirectory-files","text":"{sample_id}.summary.csv - summary of the mapping. See below for details. {sample_id}.x.{genome_id}.bam - output of mapping {sample_id}.x.{genome_id}.depth.txt - output of samtools depth {sample_id}.x.{genome_id}.count_mapped_reads.txt - output of samtools view -c {sample_id}.x.{genome_id}.leftover.fq.gz - reads remaining after reads from earlier-rank gather results are mapped (only in mapping/ subdirectory) {sample_id}.x.{genome_id}.mapped.fq.gz - all of the mapped reads {sample_id}.x.{genome_id}.overlap.fq.gz - ... {sample_id}.x.{genome_id}.bcf - output of samtools mpileup and samtools call (BCF file) {sample_id}.x.{genome_id}.vcf.gz - output of samtools mpileup and samtools call (VCF file) {sample_id}.x.{genome_id}.vcf.gz.csi - ancillary output of samtools mpileup and samtools call","title":"mapping/ and leftover/ subdirectory files"},{"location":"output-guide/#mapping-summary-file-metagenomesummarycsv-in-mapping-and-leftover","text":"these files are produced by genome_grist/summarize_mapping.py and contains one row for each genome in {metagenome} , with the following columns: index - index column unique to each row. Equivalent to genome_id . genome_id - genome identifier. sample_id - metagenome/sample identifier. n_chrom - number of contigs in the genome. n_snps - number of SNPs in the genome relative to the metagenome reads (as called by samtools call ). n_genome_bp - size of genome in bp. n_missed_bp - the number of positions in the genome with 0 coverage. f_missed_bp - the fraction of the genome that has no matches: missed / genome_bp . avg_coverage - average coverage of genome; includes bases with 0 coverage. effective_coverage - sum of depth divided by number of covered bases; does not include bases with 0 coverage. n_covered_bp - the number of bp covered by at least one read. f_covered_bp - fraction of bp covered by at least one read, aka read-mapping-based \"detection\". n_mapped_reads - total count of primary mapped reads.","title":"mapping summary file: {metagenome}.summary.csv in /mapping/ and /leftover/"},{"location":"quickstart/","text":"A genome-grist quickstart Installation We suggest installing in an isolated conda environment. The following will create a new environment, activate it, and install the latest version of genome-grist from PyPI (which is ). Run: conda create -y -n grist python=3.12 pip conda activate grist python -m pip install genome-grist Note: genome-grist should run in Python 3.11 onwards (as of June 2025). Running genome-grist We currently recommend running genome-grist in its own directory, for several reasons; in particular, genome-grist uses snakemake and conda to install software under the working directory, and it's nice to have all of files be shared. Within the current working directory, genome-grist will create a genbank_cache/ subdir, and any outputs.NAME/ subdirectories requested by the configuration. We recommend always running genome-grist in this directory and naming the output directories after the different projects using genome-grist. So, create a subdirectory and change into it: mkdir grist/ cd grist/ Note, genome-grist works entirely within the current working directory and temp directories. Download a small example database Download the GTDB rs226 set of 143,614 species-level genomes, in a pre-prepared sourmash database format: curl -LO https://farm.cse.ucdavis.edu/~ctbrown/sourmash-db/gtdb-rs226/gtdb-rs226-reps.k31.sig.zip You can use any sourmash database with Genbank identifiers with genome-grist; see available databases for more info. You can also use private databases; see the configuration docs for more info. Make a configuration file Put the following in a config file named conf-tutorial.yml : samples: - SRR5950647 outdir: outputs.tutorial/ sourmash_databases: - gtdb-rs226-reps.k31.sig.zip Do your first real run! Execute: genome-grist run conf-tutorial.yml summarize_gather summarize_mapping This will perform the following steps: download the SRR5950647 metagenome from the Sequence Read Archive (target download_reads ). preprocess it to remove adapters and low-quality reads (target trim_reads ). build a sourmash signature from the preprocess reads. (target smash_reads ). perform a sourmash gather against the specified database (target gather_reads ). download the matching genomes from GenBank into genbank_cache/ (target download_matching_genomes ). map the metagenome reads to the various genomes (target map_reads ). produce two summary notebooks (targets summarize_gather and summarize_mapping ). You can put one or more targets on the command line as above with summarize_gather and summarize_mapping . Output files Some key output files under the outputs directory are: gather/{sample}.gather.out - human-readable output from sourmash gather . gather/{sample}.gather.csv - sourmash gather CSV output . gather/genomes/ - all of the genomes found across all of the samples. gather/{sample}.genomes.info.csv - information about the matching genomes from genbank. mapping/{sample}.summary.csv - summary information about mapped reads reports/report-{sample}.html - a summary report. trim/{sample}.trim.fq.gz - trimmed and preprocessed reads. sigs/{sample}.trim.sig.zip - sourmash signature for the preprocessed reads. Note that genome-grist run <config.yml> zip will create a file named <output_dir>.zip with the above files in it. Please see the guide to genome-grist output files for more information!","title":"Quickstart"},{"location":"quickstart/#a-genome-grist-quickstart","text":"","title":"A genome-grist quickstart"},{"location":"quickstart/#installation","text":"We suggest installing in an isolated conda environment. The following will create a new environment, activate it, and install the latest version of genome-grist from PyPI (which is ). Run: conda create -y -n grist python=3.12 pip conda activate grist python -m pip install genome-grist Note: genome-grist should run in Python 3.11 onwards (as of June 2025).","title":"Installation"},{"location":"quickstart/#running-genome-grist","text":"We currently recommend running genome-grist in its own directory, for several reasons; in particular, genome-grist uses snakemake and conda to install software under the working directory, and it's nice to have all of files be shared. Within the current working directory, genome-grist will create a genbank_cache/ subdir, and any outputs.NAME/ subdirectories requested by the configuration. We recommend always running genome-grist in this directory and naming the output directories after the different projects using genome-grist. So, create a subdirectory and change into it: mkdir grist/ cd grist/ Note, genome-grist works entirely within the current working directory and temp directories.","title":"Running genome-grist"},{"location":"quickstart/#download-a-small-example-database","text":"Download the GTDB rs226 set of 143,614 species-level genomes, in a pre-prepared sourmash database format: curl -LO https://farm.cse.ucdavis.edu/~ctbrown/sourmash-db/gtdb-rs226/gtdb-rs226-reps.k31.sig.zip You can use any sourmash database with Genbank identifiers with genome-grist; see available databases for more info. You can also use private databases; see the configuration docs for more info.","title":"Download a small example database"},{"location":"quickstart/#make-a-configuration-file","text":"Put the following in a config file named conf-tutorial.yml : samples: - SRR5950647 outdir: outputs.tutorial/ sourmash_databases: - gtdb-rs226-reps.k31.sig.zip","title":"Make a configuration file"},{"location":"quickstart/#do-your-first-real-run","text":"Execute: genome-grist run conf-tutorial.yml summarize_gather summarize_mapping This will perform the following steps: download the SRR5950647 metagenome from the Sequence Read Archive (target download_reads ). preprocess it to remove adapters and low-quality reads (target trim_reads ). build a sourmash signature from the preprocess reads. (target smash_reads ). perform a sourmash gather against the specified database (target gather_reads ). download the matching genomes from GenBank into genbank_cache/ (target download_matching_genomes ). map the metagenome reads to the various genomes (target map_reads ). produce two summary notebooks (targets summarize_gather and summarize_mapping ). You can put one or more targets on the command line as above with summarize_gather and summarize_mapping .","title":"Do your first real run!"},{"location":"quickstart/#output-files","text":"Some key output files under the outputs directory are: gather/{sample}.gather.out - human-readable output from sourmash gather . gather/{sample}.gather.csv - sourmash gather CSV output . gather/genomes/ - all of the genomes found across all of the samples. gather/{sample}.genomes.info.csv - information about the matching genomes from genbank. mapping/{sample}.summary.csv - summary information about mapped reads reports/report-{sample}.html - a summary report. trim/{sample}.trim.fq.gz - trimmed and preprocessed reads. sigs/{sample}.trim.sig.zip - sourmash signature for the preprocessed reads. Note that genome-grist run <config.yml> zip will create a file named <output_dir>.zip with the above files in it. Please see the guide to genome-grist output files for more information!","title":"Output files"}]}