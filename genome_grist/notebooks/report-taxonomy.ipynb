{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pylab\n",
    "import math\n",
    "import pandas as pd\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from sourmash.lca import lca_utils\n",
    "from sourmash.lca.lca_utils import LineagePair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#sample_id='SRR5950647'\n",
    "#outdir = 'outputs.test'\n",
    "sample_id='SRR606249'\n",
    "outdir = 'outputs.paper'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# genome-grist taxonomic summary for metagenome `SRR606249`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown as md\n",
    "from IPython.display import display\n",
    "md(f\"# genome-grist taxonomic summary for metagenome `{sample_id}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load gather CSV + taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../../outputs.paper/gathertax/SRR606249.x.genbank.gather.with-lineages.csv does not exist: '../../outputs.paper/gathertax/SRR606249.x.genbank.gather.with-lineages.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b00f43b70f67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load gather CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtax_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'../../{outdir}/gathertax/{sample_id}.x.genbank.gather.with-lineages.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ../../outputs.paper/gathertax/SRR606249.x.genbank.gather.with-lineages.csv does not exist: '../../outputs.paper/gathertax/SRR606249.x.genbank.gather.with-lineages.csv'"
     ]
    }
   ],
   "source": [
    "# load gather CSV\n",
    "tax_df = pd.read_csv(f'../../{outdir}/gathertax/{sample_id}.x.genbank.gather.with-lineages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_ranks = ['superkingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species']\n",
    "\n",
    "# \"fix\" lineage column,\n",
    "def split_lineages(x):\n",
    "#    print((x, type(x)))\n",
    "    if isinstance(x, float) and math.isnan(x):\n",
    "        return ()\n",
    "\n",
    "    ret = []\n",
    "    for (rank, name) in zip(tax_ranks, x.split(';')):\n",
    "        ret.append(LineagePair(rank, name))\n",
    "    return tuple(ret)\n",
    "    \n",
    "tax_df['lineage'] = tax_df['lineage'].apply(split_lineages)\n",
    "\n",
    "# and break it up into tuples\n",
    "\n",
    "def grab_tax(x, idx):\n",
    "    if x:\n",
    "        return x[idx].name\n",
    "    return ''\n",
    "\n",
    "for idx, rank in enumerate(tax_ranks):\n",
    "    tax_df[rank] = tax_df['lineage'].apply(grab_tax, args=(idx,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function that aggregates various pieces of information by rank & builds a new df\n",
    "def aggregate_by_rank(df, rank):\n",
    "    # first, build all the counts\n",
    "    unique_intersect_by_rank = defaultdict(int)\n",
    "    f_intersect_by_rank = defaultdict(int)\n",
    "    best_hashes_by_rank = {}\n",
    "\n",
    "    def sum_unique(row):\n",
    "        lin = row.lineage\n",
    "        if pd.isnull(lin):\n",
    "            lin = []\n",
    "        unique_hashes = row.unique_intersect_bp\n",
    "        f_hashes = row.f_unique_to_query\n",
    "\n",
    "        for rank in ('superkingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species'):\n",
    "            poplin = lca_utils.pop_to_rank(lin, rank)\n",
    "            unique_intersect_by_rank[poplin] += unique_hashes\n",
    "            f_intersect_by_rank[poplin] += f_hashes\n",
    "            \n",
    "            best_hashes = best_hashes_by_rank.get(poplin, 0)\n",
    "            if best_hashes < unique_hashes:\n",
    "                best_hashes_by_rank[poplin] = unique_hashes\n",
    "\n",
    "    df.apply(sum_unique, axis=1)\n",
    "\n",
    "    # now do the sorting etc.\n",
    "    rank_counts = []\n",
    "    for lin, bp in sorted(unique_intersect_by_rank.items(), key=lambda x: -x[1]):\n",
    "        if lin and lin[-1].rank == rank:\n",
    "            \n",
    "            f_unique = f_intersect_by_rank[lin]\n",
    "            if rank == 'species':\n",
    "                name = lin[-1].name\n",
    "                name = f'{name} ({lin[0].name})'\n",
    "            elif rank == 'genus':\n",
    "                name = lin[-1].name\n",
    "                name = f'{name}'\n",
    "            else:\n",
    "                name = lca_utils.display_lineage(lin)\n",
    "\n",
    "            rank_counts.append(dict(name=name, hashes=bp, f_unique=f_unique,\n",
    "                                    best_hashes=best_hashes_by_rank[lin],\n",
    "                                    lineage=lin))\n",
    "            \n",
    "    name = \"unclassified\"\n",
    "    hashes = 0 # CTB fixme\n",
    "    f_unique = 1 - sum(v for (k, v) in f_intersect_by_rank.items() if k and k[-1].rank == rank )\n",
    "    best_hashes = 0 # CTB\n",
    "    lineage = ()\n",
    "    rank_counts.append(dict(name=name, hashes=bp, f_unique=f_unique,\n",
    "                            best_hashes=best_hashes_by_rank[lin],\n",
    "                            lineage=lin))    \n",
    "\n",
    "    return pd.DataFrame(rank_counts)\n",
    "\n",
    "species_df = aggregate_by_rank(tax_df, 'species')\n",
    "genus_df = aggregate_by_rank(tax_df, 'genus')\n",
    "family_df = aggregate_by_rank(tax_df, 'family')\n",
    "order_df = aggregate_by_rank(tax_df, 'order')\n",
    "class_df = aggregate_by_rank(tax_df, 'class')\n",
    "phylum_df = aggregate_by_rank(tax_df, 'phylum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 'species'\n",
    "plot_df = species_df\n",
    "\n",
    "pylab.figure(num=None, figsize=(10, 10))\n",
    "\n",
    "plot_df = plot_df[:40]\n",
    "#pylab.plot(plot_df.hashes, plot_df.iloc[::-1].index, 'bo', label='hashes')\n",
    "pylab.plot(plot_df.f_unique * 100, plot_df.iloc[::-1].index, 'ro', label='percent of metagenome')\n",
    "\n",
    "positions = list(plot_df.index)\n",
    "labels = list(reversed(plot_df.name))\n",
    "pylab.yticks(positions, labels, fontsize='small')\n",
    "\n",
    "pylab.xlabel('bp')\n",
    "pylab.axis(xmin=0)\n",
    "pylab.legend(loc='lower right')\n",
    "pylab.title(f'{sample_id}: metagenome classification, by {rank}')\n",
    "pylab.tight_layout()\n",
    "\n",
    "#figname = f'/tmp/gathergram-{rank}-{sample_id}.png'\n",
    "#print(f'saving to {figname}')\n",
    "#pylab.savefig(figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 'genus'\n",
    "plot_df = genus_df\n",
    "\n",
    "pylab.figure(num=None, figsize=(10, 10))\n",
    "\n",
    "plot_df = plot_df[:40]\n",
    "#pylab.plot(plot_df.hashes, plot_df.iloc[::-1].index, 'bo', label='hashes')\n",
    "pylab.plot(plot_df.f_unique * 100, plot_df.iloc[::-1].index, 'ro', label='percent of metagenome')\n",
    "\n",
    "positions = list(plot_df.index)\n",
    "labels = list(reversed(plot_df.name))\n",
    "pylab.yticks(positions, labels, fontsize='small')\n",
    "\n",
    "pylab.xlabel('bp')\n",
    "pylab.axis(xmin=0)\n",
    "pylab.legend(loc='lower right')\n",
    "pylab.title(f'{sample_id}: metagenome classification, by {rank}')\n",
    "pylab.tight_layout()\n",
    "\n",
    "#figname = f'/tmp/gathergram-{rank}-{sample_id}.png'\n",
    "#print(f'saving to {figname}')\n",
    "#pylab.savefig(figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 'family'\n",
    "plot_df = family_df\n",
    "\n",
    "pylab.figure(num=None, figsize=(10, 10))\n",
    "\n",
    "plot_df = plot_df[:40]\n",
    "#pylab.plot(plot_df.hashes, plot_df.iloc[::-1].index, 'bo', label='hashes')\n",
    "pylab.plot(plot_df.f_unique * 100, plot_df.iloc[::-1].index, 'ro', label='percent of metagenome')\n",
    "\n",
    "positions = list(plot_df.index)\n",
    "labels = list(reversed(plot_df.name))\n",
    "pylab.yticks(positions, labels, fontsize='small')\n",
    "\n",
    "pylab.xlabel('bp')\n",
    "pylab.axis(xmin=0)\n",
    "pylab.legend(loc='lower right')\n",
    "pylab.title(f'{sample_id}: metagenome classification, by {rank}')\n",
    "pylab.tight_layout()\n",
    "\n",
    "#figname = f'/tmp/gathergram-{rank}-{sample_id}.png'\n",
    "#print(f'saving to {figname}')\n",
    "#pylab.savefig(figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 'order'\n",
    "plot_df = order_df\n",
    "\n",
    "pylab.figure(num=None, figsize=(10, 10))\n",
    "\n",
    "plot_df = plot_df[:40]\n",
    "#pylab.plot(plot_df.hashes, plot_df.iloc[::-1].index, 'bo', label='hashes')\n",
    "pylab.plot(plot_df.f_unique * 100, plot_df.iloc[::-1].index, 'ro', label='percent of metagenome')\n",
    "\n",
    "positions = list(plot_df.index)\n",
    "labels = list(reversed(plot_df.name))\n",
    "pylab.yticks(positions, labels, fontsize='small')\n",
    "\n",
    "pylab.xlabel('bp')\n",
    "pylab.axis(xmin=0)\n",
    "pylab.legend(loc='lower right')\n",
    "pylab.title(f'{sample_id}: metagenome classification, by {rank}')\n",
    "pylab.tight_layout()\n",
    "\n",
    "#figname = f'/tmp/gathergram-{rank}-{sample_id}.png'\n",
    "#print(f'saving to {figname}')\n",
    "#pylab.savefig(figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 'class'\n",
    "plot_df = class_df\n",
    "\n",
    "pylab.figure(num=None, figsize=(10, 10))\n",
    "\n",
    "plot_df = plot_df[:40]\n",
    "#pylab.plot(plot_df.hashes, plot_df.iloc[::-1].index, 'bo', label='hashes')\n",
    "pylab.plot(plot_df.f_unique * 100, plot_df.iloc[::-1].index, 'ro', label='percent of metagenome')\n",
    "\n",
    "positions = list(plot_df.index)\n",
    "labels = list(reversed(plot_df.name))\n",
    "pylab.yticks(positions, labels, fontsize='small')\n",
    "\n",
    "pylab.xlabel('bp')\n",
    "pylab.axis(xmin=0)\n",
    "pylab.legend(loc='lower right')\n",
    "pylab.title(f'{sample_id}: metagenome classification, by {rank}')\n",
    "pylab.tight_layout()\n",
    "\n",
    "#figname = f'/tmp/gathergram-{rank}-{sample_id}.png'\n",
    "#print(f'saving to {figname}')\n",
    "#pylab.savefig(figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 'phylum'\n",
    "plot_df = phylum_df\n",
    "\n",
    "pylab.figure(num=None, figsize=(10, 10))\n",
    "\n",
    "plot_df = plot_df[:40]\n",
    "#pylab.plot(plot_df.hashes, plot_df.iloc[::-1].index, 'bo', label='hashes')\n",
    "pylab.plot(plot_df.f_unique * 100, plot_df.iloc[::-1].index, 'ro', label='percent of metagenome')\n",
    "\n",
    "positions = list(plot_df.index)\n",
    "labels = list(reversed(plot_df.name))\n",
    "pylab.yticks(positions, labels, fontsize='small')\n",
    "\n",
    "pylab.xlabel('bp')\n",
    "pylab.axis(xmin=0)\n",
    "pylab.legend(loc='lower right')\n",
    "pylab.title(f'{sample_id}: metagenome classification, by {rank}')\n",
    "pylab.tight_layout()\n",
    "\n",
    "#figname = f'/tmp/gathergram-{rank}-{sample_id}.png'\n",
    "#print(f'saving to {figname}')\n",
    "#pylab.savefig(figname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
