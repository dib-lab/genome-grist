{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "sample_id = 'twofoo-head'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def load_csv(filename, key):\n",
    "    rows = {}\n",
    "    with open(filename, 'rt') as fp:\n",
    "        r = csv.DictReader(fp)\n",
    "        for row in r:\n",
    "            k = row[key]\n",
    "            rows[k] = row\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load mapping summary CSVs and gather CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_map = load_csv(f'../../outputs/minimap/depth/{sample_id}.summary.csv', 'genome_id')\n",
    "left_map = load_csv(f'../../outputs/leftover/depth/{sample_id}.summary.csv', 'genome_id')\n",
    "gather_csv_raw = load_csv(f'../../outputs/{sample_id}.gather.csv', 'name')\n",
    "\n",
    "def fix_name(x):\n",
    "    return \"_\".join(x.split('_')[:2]).split('.')[0]\n",
    "\n",
    "gather_csv = {}\n",
    "for k in gather_csv_raw:\n",
    "    genome_id = fix_name(k)\n",
    "    gather_csv[genome_id] = gather_csv_raw[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(set(all_map.keys()) - set(left_map.keys()))\n",
    "print(set(all_map.keys()) - set(left_map.keys()))\n",
    "print(set(all_map.keys()) - set(gather_csv.keys()))\n",
    "for k in set(gather_csv.keys()) - set(all_map.keys()):\n",
    "    del gather_csv[k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('', 'GCA_000017325'),\n",
      "             ('genome bp', '5312910'),\n",
      "             ('missed', '4094498'),\n",
      "             ('percent missed', '77.06695577376617'),\n",
      "             ('coverage', '0.9088284951184944'),\n",
      "             ('genome_id', 'GCA_000017325'),\n",
      "             ('sample_id', 'twofoo-head')])\n",
      "OrderedDict([('intersect_bp', '894000'),\n",
      "             ('f_orig_query', '0.47502656748140276'),\n",
      "             ('f_match', '0.17268688429592427'),\n",
      "             ('f_unique_to_query', '0.47502656748140276'),\n",
      "             ('f_unique_weighted', '0.45027338554750995'),\n",
      "             ('average_abund', '3.4082774049217'),\n",
      "             ('median_abund', '2.0'),\n",
      "             ('std_abund', '10.542975796396597'),\n",
      "             ('name',\n",
      "              'GCA_000017325.1 Shewanella baltica OS185 strain=OS185, '\n",
      "              'ASM1732v1'),\n",
      "             ('filename',\n",
      "              '/home/irber/sourmash_databases/outputs/sbt/genbank-bacteria-x1e5-k31.sbt.zip'),\n",
      "             ('md5', '09a08691ce52952152f0e866a59f6261'),\n",
      "             ('f_match_orig', '0.17268688429592427')])\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "genome_id = next(iter(gather_csv.keys()))\n",
    "pprint.pprint(all_map[genome_id])\n",
    "pprint.pprint(gather_csv[genome_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total bp mapped: 2.305963e+06\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'unique_intersect_bp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-dc2717687d22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtotal_hashes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenome_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgather_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtotal_hashes\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgather_csv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenome_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unique_intersect_bp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# XXX @CTB unique_intersect_bp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'total hashes identified: {total_hashes:e}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'unique_intersect_bp'"
     ]
    }
   ],
   "source": [
    "total_bp_mapped = 0\n",
    "for n, genome_id in enumerate(gather_csv):\n",
    "    genome_bp = float(left_map[genome_id]['genome bp'])\n",
    "    percent_missed = float(left_map[genome_id]['percent missed'])\n",
    "    f_mapped = 1 - (percent_missed/ 100)\n",
    "    total_bp_mapped += genome_bp * f_mapped\n",
    "    \n",
    "print(f'total bp mapped: {total_bp_mapped:e}')\n",
    "\n",
    "total_hashes = 0\n",
    "for n, genome_id in enumerate(gather_csv):\n",
    "    total_hashes += int(gather_csv[genome_id]['unique_intersect_bp']) # XXX @CTB unique_intersect_bp\n",
    "    \n",
    "print(f'total hashes identified: {total_hashes:e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fig 1: examining leftover reads, in order of gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y1 = []\n",
    "y2 = []\n",
    "for n, genome_id in enumerate(gather_csv):\n",
    "    x.append(n)\n",
    "    f_match = float(gather_csv[genome_id]['f_match']) * 100\n",
    "    percent_missed = float(left_map[genome_id]['percent missed'])\n",
    "    x.append(n)\n",
    "    y1.append(f_match)\n",
    "    y2.append(100 - percent_missed)\n",
    "\n",
    "pylab.plot(y1, y2, '.')\n",
    "pylab.xlim(0, 100)\n",
    "pylab.ylim(0, 100)\n",
    "pylab.xlabel('f_match')\n",
    "pylab.ylabel('mapping bp covered')\n",
    "pylab.title('gather f_match vs leftover mapping bp covered')\n",
    "pylab.plot([0, 100], [0, 100], '--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fig 2: fraction of hashes unique to query, in order of gather results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y1 = []\n",
    "for n, genome_id in enumerate(gather_csv):\n",
    "    f_match = float(gather_csv[genome_id]['f_unique_to_query']) * 100\n",
    "    percent_missed = float(left_map[genome_id]['percent missed'])\n",
    "    x.append(n)\n",
    "    y1.append(f_match)\n",
    "\n",
    "pylab.plot(x, y1, '.')\n",
    "pylab.title('fraction of hashes unique to query')\n",
    "pylab.xlabel('gather rank order')\n",
    "pylab.ylabel('f_unique_to_query, as %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fig 3: read counts by sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    read_counts = {}\n",
    "    with open('leftover.read-counts.txt', 'rt') as fp:\n",
    "        for line in fp:\n",
    "            genome_n, counts = line.split()\n",
    "            genome_n = int(genome_n)\n",
    "            counts = int(counts)\n",
    "            read_counts[genome_n] = counts\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for n, genome_id in enumerate(gather_csv):\n",
    "        x.append(n)\n",
    "        y.append(read_counts[int(genome_id)])\n",
    "\n",
    "    pylab.plot(x, y, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fig 4: sum mapped bp and sum identified hashes, in order of gather\n",
    "\n",
    "conclusion: across the gather run, total hashes identified correlate well with total bp mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_x = []\n",
    "map_bp_mapped = []\n",
    "map_bp_unmapped = []\n",
    "\n",
    "sofar = 0\n",
    "for n, genome_id in enumerate(gather_csv):\n",
    "    genome_bp = float(left_map[genome_id]['genome bp'])\n",
    "    percent_missed = float(left_map[genome_id]['percent missed'])\n",
    "    f_mapped = 1 - (percent_missed / 100)\n",
    "    bp_mapped = genome_bp * f_mapped\n",
    "    \n",
    "    sofar += bp_mapped\n",
    "    \n",
    "    map_x.append(n)\n",
    "    map_bp_mapped.append(bp_mapped)\n",
    "    map_bp_unmapped.append(sofar)\n",
    "    \n",
    "hash_x = []\n",
    "hash_n_ident = []\n",
    "hash_n_classified = []\n",
    "\n",
    "sofar = 0\n",
    "for n, genome_id in enumerate(gather_csv):\n",
    "    n_hashes = int(gather_csv[genome_id]['unique_intersect_bp']) # XXX @CTB unique_intersect_bp\n",
    "    sofar += n_hashes\n",
    "    hash_x.append(n)\n",
    "    hash_n_ident.append(n_hashes)\n",
    "    hash_n_classified.append(sofar)\n",
    "\n",
    "pylab.plot(map_x, map_bp_unmapped, '-', label='total mapped bp')\n",
    "pylab.plot(hash_x, hash_n_classified, '.', label='total classified hashes')\n",
    "\n",
    "pylab.xlabel('genome in rank order of gather')\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.title(f'{sample_id}: gather remaining hashes vs remaining bp')\n",
    "pylab.savefig(f'/tmp/gather-{sample_id}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fig 5: mapped bp and identified hashes compared by sample, in order of gather\n",
    "\n",
    "conclusion: for most samples, bp mapped to that genome matches # of hashes classified to that genome\n",
    "\n",
    "note: hashes classified to this genome is monotonically decreasing, b/c gather is a greedy algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.plot(map_x, map_bp_mapped, '.', label='mapped bp to this genome')\n",
    "pylab.plot(hash_x, hash_n_ident, '.', label='hashes classified for this genome')\n",
    "\n",
    "pylab.xlabel('genome in rank order of gather')\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.title(f'{sample_id}: gather hashes vs mapped bp')\n",
    "pylab.savefig(f'/tmp/gather-{sample_id}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fig 6: difference between sum hash ident and sum bp mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydiff = [ h - m for (h, m) in zip(hash_n_classified, map_bp_unmapped)]\n",
    "x = range(len(ydiff))\n",
    "pylab.plot(x, ydiff, '.-')\n",
    "pylab.xlabel('genome (ordered by gather results)')\n",
    "pylab.ylabel('difference: total hashcount - mapped bp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fig 7: difference between hashes and bp, per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.plot(map_x, map_bp_mapped, '.', label='mapped bp to this genome')\n",
    "pylab.plot(hash_x, hash_n_ident, '.', label='hashes classified for this genome')\n",
    "\n",
    "ydiff = [ h - m for (h, m) in zip(hash_n_ident, map_bp_mapped)]\n",
    "x = range(len(ydiff))\n",
    "pylab.plot(x, ydiff, '.-', label='difference b/t hashes and mapping')\n",
    "pylab.xlabel('genome (ordered by gather results)')\n",
    "#pylab.ylabel('difference: hashcount - mapped bp')\n",
    "pylab.ylabel('number per genome')\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.title(f'{sample_id}: gather hashes vs mapped bp')\n",
    "pylab.savefig(f'/tmp/gather-{sample_id}.pdf')\n",
    "pylab.savefig(f'/tmp/gather-{sample_id}.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
